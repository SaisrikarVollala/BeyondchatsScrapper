# BeyondChats Scraper

A robust web scraping application built with TypeScript, Express, and MongoDB for extracting and storing web data efficiently.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Tech Stack](#tech-stack)
- [Local Setup Instructions](#local-setup-instructions)
- [Project Structure](#project-structure)
- [Architecture](#architecture)
- [API Documentation](#api-documentation)


## âœ¨ Features

- Web scraping with Cheerio
- RESTful API with Express
- MongoDB database integration
- TypeScript for type safety
- Environment-based configuration
- Modular architecture

## ğŸ›  Tech Stack

- **Runtime**: Node.js (v20.19.0+)
- **Language**: TypeScript 5.9.3
- **Framework**: Express 5.2.1
- **Database**: MongoDB with Mongoose 9.0.2
- **HTTP Client**: Axios 1.13.2
- **Web Scraper**: Cheerio 1.1.2
- **Environment Management**: dotenv 17.2.3


## ğŸš€ Local Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/SaisrikarVollala/BeyondchatsScrapper.git
cd beyondchats-scraper
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Set Up Environment Variables

Create a `.env` file in the root directory:

```bash
touch .env
```

Add the following environment variables:

```env
# Server Configuration
PORT=3000

# Database Configuration
MONGODB_URI=mongodb://localhost:27017/beyondchats

# For MongoDB Atlas (alternative):
# MONGODB_URI=mongodb+srv://<username>:<password>@<cluster>.mongodb.net/beyondchats
```

### 4. Start MongoDB

**For Local MongoDB:**

```bash
# macOS (with Homebrew)
brew services start mongodb-community

# Linux
sudo systemctl start mongod

# Windows
net start MongoDB
```

**For MongoDB Atlas:**
- Ensure your connection string is correctly set in `.env`
- Whitelist your IP address in MongoDB Atlas dashboard

### 5. Build the Project

```bash
npm run build
```

This compiles TypeScript files from `src/` to JavaScript in `dist/`.

### 6. Run the Application
**Production Mode:**

```bash
npm start
```

The server will start on `http://localhost:3000` (or your configured PORT).

You should receive a success response if everything is set up correctly.

## ğŸ“ Project Structure

```
beyondchats-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ db.ts           # Database connection configuration
â”‚   â”‚   â””â”€â”€ env.ts          # Environment variables management
â”‚   â”œâ”€â”€ models/             # Mongoose schemas and models
â”‚   â”œâ”€â”€ routes/             # Express route definitions
â”‚   â”œâ”€â”€ controllers/        # Request handlers and business logic
â”‚   â”œâ”€â”€ services/           # Scraping and data processing services
â”‚   â”œâ”€â”€ utils/              # Helper functions and utilities
â”‚   â””â”€â”€ index.ts            # Application entry point
â”œâ”€â”€ dist/                   # Compiled JavaScript (generated)
â”œâ”€â”€ node_modules/           # Dependencies
â”œâ”€â”€ .env                    # Environment variables (create this)
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ package.json           # Project metadata and scripts
â”œâ”€â”€ tsconfig.json          # TypeScript configuration
â””â”€â”€ README.md              # This file
```

## Architecture

### Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚  (Browser)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP Request
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Express Server              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Routes Layer             â”‚  â”‚
â”‚  â”‚  (API Endpoints)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                       â”‚
â”‚              â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Controllers Layer          â”‚  â”‚
â”‚  â”‚  (Request Handling)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                       â”‚
â”‚              â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Services Layer             â”‚  â”‚
â”‚  â”‚  â€¢ Web Scraping (Cheerio)     â”‚  â”‚
â”‚  â”‚  â€¢ Data Processing            â”‚  â”‚
â”‚  â”‚  â€¢ Business Logic             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Database Layer              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Mongoose Models            â”‚  â”‚
â”‚  â”‚  (Schema Definitions)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                       â”‚
â”‚              â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚       MongoDB                 â”‚  â”‚
â”‚  â”‚  (Data Persistence)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  External Sites â”‚
     â”‚  (Scraping      â”‚
     â”‚   Targets)      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Descriptions

#### 1. **Express Server**
- Entry point: `src/index.ts`
- Handles HTTP requests and responses
- Middleware for parsing, validation, and error handling

#### 2. **Routes Layer**
- Defines API endpoints
- Maps URLs to controller functions
- Handles request routing

#### 3. **Controllers Layer**
- Processes incoming requests
- Validates input data
- Calls appropriate services
- Formats and returns responses

#### 4. **Services Layer**
- **Scraping Service**: Uses Axios and Cheerio to fetch and parse web pages
- **Data Processing**: Cleans and transforms scraped data
- **Business Logic**: Implements core application functionality

#### 5. **Database Layer**
- **Mongoose Models**: Define data schemas and relationships
- **MongoDB**: Persistent storage for scraped data
- Handles CRUD operations

#### 6. **External Sites**
- Target websites for scraping
- Axios fetches HTML content
- Cheerio parses and extracts data

## ğŸ“š API Documentation





**Built with â¤ï¸ by Srikar**